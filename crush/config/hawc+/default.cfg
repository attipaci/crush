# ===========================================================================
# CRUSH default configuration for SOFIA/HAWC+
#
# Author: Attila Kovacs <attila[AT]sigmyne.com>
# Description:
# 	This configuration file is automatically loaded when crush is started
#       with hawc+ as the instrument. Users may define their own startup
#       configuration in ~/.crush2/hawc+/default.cfg which will be parsed
#       immediately after the global defaults contained here.
# See: crush/README, crush/hawc+/README
# ===========================================================================

# Load SOFIA defaults
config sofia/default.cfg

# The ordering of models in the default reduction pipeline. 
ordering dejump, offsets, drifts, correlated.obs-channels, correlated.sky, correlated.nonlinearity, correlated.polarrays, correlated.telescope-x, correlated.chopper-x, correlated.chopper-y, correlated.los, correlated.pitch, correlated.roll, correlated.accel-|y|, weighting.frames, filter, weighting, despike, correlated.subarrays, correlated.gradients, correlated.bias, correlated.series, correlated.mux, correlated.rows, source

# Set keywords identifying specific runs/periods...
date.[*--2016.07.01] apr2016
date.[2016.09.01--2016.11.01] oct2016
date.[2016.11.30--2016.12.20] dec2016
date.[2017.10.01--2017.12.01] oct2017

# Select specific subarrays only. E.g. if pointing to the center of R0, then
# reduce R0/T0 only...
fits.[SIBS_X?15.5] subarray T0,R0

# Reduce skydips with R0 only (least non-linear)
[source.type?skydip] subarray R0
[source.type?skydip] subarray.lock

# Transfer FITS header keys to configuration options...
fits.assign.DIAG_HZ intcalfreq

# If 'calibrated' is set, CRUSH will produce Level 3 data for single scans
# Otherwise, the default is to produce Level 2 data for single scans
#calibrated

# Specify the unit of the raw data
dataunit counts

# Specify the output units
unit Jy/beam
#unit Jy/pixel

# Use the 'peakflux' option
[peakflux] scale 1.18

# The gain conversion to readout units
gain -1.0

# Assumes sign of source signals +, -, or 0
source.sign +

# The appropriate Jy/K conversion value (assuming 2.5m, 95% forward eff.)
K2Jy 582

# starting Oct 2016 run, assume real-time object coordinates (rtoc) are 
# recorded in the FITS for all sourcess, regardless of whether they are 
# sidereal or not.
rtoc

# Use data recorded between scans
#betweenscans

# The minimum length of a valid scan in seconds.
subscan.minlength 5.0

# Shift data relative to coordinates by the specified amount (seconds).
shift -0.014

# Shift chopper data to align with detectors
chopper.shift 2

# Set a tolerance (arcsec) for the chopper signal. It has to be within the 
# nominal amplitude value for the frame to be used. This is useful to avoid 
# smearing when reducing chopped data...
chopper.tolerance 10

# Discard slow scanning frames with entirely (instead of just flagging them).
vclip.strict

# Allow velocity clip for chopped data (mapping mode)
[chopped] recall vclip

# Apply correction for gyro drifts
[oct2017] gyrocorrect

# Set a limit to what's the largest gyro drift that can be corrected...
# (in arcsec)
gyrocorrect.max 30

# Map even if many pixels are flagged
mappingfraction 0.2

# Use the faster maximum-likelihood estimation from the start...
estimator maximum-likelihood

# Set the initial 1/f timescale..
drifts 30

# When using non-linear response corrections, make sure the drift window covers
# the entire scan...
[correlated.nonlinearity] drifts max

# 1/f stability timescale in seconds
stability 5.0
[extended] stability 10.0

# Use shorter 'stability' timescale for short scans, such as focus scans, to
# get the crispest possible images...
obstime.[<45] stability 2.5

# Flag some MUX lines that seem to be always bad...
flag.mux 6,20,24,27-34,40,46-48,50,63,70,86

# Flag only MUXes that seem really dead
# flag.mux 6,20,27-32,46-48,50,70,86

# Flag only MUXes that seem to produce crazy source reponse
# flag.mux 24,33,34,40,49,63,127

# Flag rows that seem always bad
flag.row 2,19,52,82,83,87,114,122,65,69,77

# Flag only rows that seem to be blind...
#flag.row 2,19

# Flag only rows that seem to have strange source response...
#flag.row 82,83,87,114,122

# Flag some more baddies
#flag R1[24,16]:R1[24,31],R1[28,16]:R1[28,31],R1[36,16]:R1[36:31]

# The overall rotation of the array from crush x,y coordinates to SI x,y.
date.[*--2017.10.01] rotation 0.9
rotation 0.1

# The relative rotations of the subarrays.
rotation.R0 0.0
rotation.R1 180.0
date.[*--2017.10.01] rotation.T0 -0.5
rotation.T0 0.5
#rotation.T1 180.5


# Subarray offsets (in pixels)
offset.R0 0.0,0.0
offset.R1 67.03,39.0
date.[*--2017.10.01] offset.T0 0.18,-0.17
offset.T0 0.29,-0.27
#offset.T1 ???,???

# zoom constants (T vs R)
zoom.T 1.0

# Correct for flux jumps
date.[*--2017.05.01] jumpdata {?configpath}/hawc+/FluxjumpFS14Columns.fits.gz

# Whether 'fix' flux jumps
#iteration.[last-1] fixjumps

# Flag pixels outside an acceptable range of relative noise levels
weighting.noiserange 0.3:3.0

# Use neighbor-based despiking all the way...
despike.method.lock neighbours

# Define various shorthands for decorrelations
alias.pols correlated.polarrays
alias.subs correlated.subarrays
alias.biaslines correlated.bias
alias.mux correlated.mux
alias.rows correlated.rows
alias.series correlated.series
alias.accel correlated.accel-|y|
alias.los correlated.los
alias.roll correlated.roll

# The range of acceptable relative sky-noise gains.
array.signed
array.gainRange 0.3:3.0

# Decorrelate sky signal (separated from temperature signal)
[pixeldata] sky

# If the couplings are merged into the correlated gains, then do not
# decorrelate on sky separately...
[sourcegains] blacklist sky

# Decorrelate on polarization arrays
#pols

# Decorrelated on TES bias lines
biaslines
biaslines.gainrange 0.3:3.0

# Decorrelate on the series arrays (heat-sinking)
iteration.[last-1] series
series.nogains

# Decorrelate on SQUID multiplexed channels
#mux
mux.nogains
mux.gainrange 0.3:3.0
#iteration.[2] forget mux.nogains

# Decorrelate on detector rows (i.e. MUX address lines)
#rows
rows.gainrange 0.3:3.0

# For chopped data, remove the chopper-induced correlated signals...
[chopped] correlated.chopper-x
[chopped] correlated.chopper-y

# Remove correlations to second-derivative of LOS angle (a proxy for pitch 
# accelerations)
#los
#los.gainRange 0.3:3.0

# Remove correlations to second-derivative of roll angle
#roll
#roll.gainRange 0.3:3.0

# Activate DRP messages over TCP/IP
#drp

# Various options for the DRP messaging service...
drp.host 127.0.0.1
drp.port 50747
drp.id hawc.pipe.step.crush
drp.fifo 100
drp.timeout 1.0
drp.timestamp

# When running in the SOFIA pipeline (assuming that TCP/IP messaging enabled 
# via the 'drp' option), then disable PNG thumbnail generation to prevent any
# possinble internal Java errors due to missing/broken X11 display connections.
[drp] forget write.png

# When running reductions via the DRP, smooth images slightly for better visual
# appearance
[drp] iteration.[last] smooth halfbeam

# Use's Bill Vacca's ATRAN-based polynomial model for calculating opacity...
#tau atran

# Use the measured PWV to calculate tau...
#tau pwv

# Calculate typical PWV values, instead of using the monitor data
tau pwvmodel

# Use this model, whenever the pwv values aren't available or cannot
# be trusted...
date.[*--2016.12.01] [tau?pwv] tau pwvmodel
date.[2016.12.03--2016.12.04] [tau?pwv] tau pwvmodel

# Refer opacity relations to the PWV value (which is recorded)
tau.pwv.a 1.0
tau.pwv.b 0.0

# For an approximate 'blind' PWV model, define the mean PWV value at 41k 
# altitude 
pwv41k 22
date.[2016.10.04--2016.10.05] pwv41k 40.7

# And a scale-height in kilofeet...
pwvscale 4.38

# Never smooth focus scans...
fits.[CALMODE?Focus] iteration.[last] blacklist smooth

# Reduce skydips if OBSMODE, CALMODE or DIAGMODE is set to SKYDIP
fits.[DIAGMODE?SKYDIP] skydip
fits.[OBSMODE?SkyDip] skydip

# Fit skydips on restricted elevation range only...
skydip.elrange 0:55

# Fit only tau and the offset but not the counts/jansky scaling
skydip.fit tau,offset

# For skydips, notch out the intcal signal (203.25 Hz / 68 -- and harmonics)
[source.type?skydip] notch
[intcalfreq?!-9999.0] notch.frequencies {?intcalfreq}
notch.width 0.03
notch.harmonics 35

# Don't decorrelated the chopper signal for skydips...
[source.type?skydip] blacklist correlated.chopper-x, correlated.chopper-y
[source.type?skydip] blacklist chopped
#[source.type?skydip] write.png

# Downsample skydips by a fixed amount...
#[source.type?skydip] downsample 50

# Use only parts of the map for source flatfield estimation, which are within
# the specified S/N range...
source.coupling.s2n 5.0:500.0

# List of FITS keys to add (on top of additional SOFIA keys)
fits.addkeys {&fits.addkeys},INSTCFG

# Set the observing band based on the SPECTEL1 header value
fits.[SPECTEL1?HAW_A] band A
fits.[SPECTEL1?HAW_B] band B
fits.[SPECTEL1?HAW_C] band C
fits.[SPECTEL1?HAW_D] band D
fits.[SPECTEL1?HAW_E] band E

# Load date-based configuration overrides...
[apr2016] config hawc+/2016-04.cfg
[oct2016] config hawc+/2016-10.cfg

# Load the appropriate configuration for each band
[band?A] config band-A.cfg
[band?B] config band-B.cfg
[band?C] config band-C.cfg
[band?D] config band-D.cfg
[band?E] config band-E.cfg

# Never segment scans if using them for determining flatfields.
[write.flatfield] blacklist segment

# If dealing with demodulated data, then load the appropriate 
# settings for reducing it
fits.[PRODTYPE?demod] config demod.cfg

# logging...
obslog.format date\t flight\t scanno\t band\t object\t ?skydip\t obsmins(f1)\t chop.flag\t gyro.max(f1)\t ac.altkft(f1)\t tel.el(f1)\t env.pwv(f1)\t env.tamb(f1)\t hawc.dfoc(f1)
