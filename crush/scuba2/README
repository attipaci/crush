            *** CRUSH User's Manual Extension for the SCUBA-2 ***

                              Attila Kovacs
                        <attila[AT]submm.caltech.edu>

                        Last updated: 25 Aug 2015



Table of Contents
=================

1. Introduction
2. Quick Start
  2.1 Setup and configuration
  2.2 Reducing the first scans 
  2.3 Extended sources
3. Reading Scans
  3.1 FITS vs. SDF
  3.2 '450um' vs '850um' reduction mode
  3.3 By date and scan number
  3.4 By file names
4. Calibration and Pointing
  4.1 Extinction Correction
  4.2 Calibration Correction
  4.3 Pointing Corrections
5. SCUBA-2 specific pixel divisions
6. Glossary of SCUBA-2 specific options
7. SCUBA-2 specific log quantities



#####################################################################
1. Introduction
#####################################################################

This document contains information specific to using CRUSH-2 to reduce SCUBA-2
data. It is assumed that you are already familiar with the contents of the main
CRUSH-2 README (inside the distribution directory), especially its Section 1
(Getting Started).

If you run into difficulty following this document, you will probably find it 
useful to study the main README a little longer.



#####################################################################
2. Quick start
#####################################################################


2.1 Setup and configuration
===========================

   After you set up CRUSH (see the main README for instructions), you will also 
   need access to a Starlink installation on your machine, since the 
   SCUBA-2 proprietary data files (.sdf) can only be read through the Starlink 
   libraries. (You only really need the 'ndf2fits' tool included in 
   Starlink...)

   Once you have installed Starlink, start by creating (or editing) 
   '.crush2/scuba2/default.cfg' in your home directory (this file will contain 
   your personalized configuration entries). E.g. on UNIX and MacOS:

     > mkdir -p ~/.crush2/scuba2

   Then create/edit 'default.cfg' therein, e.g. with 'nano':

     > nano ~/.crush2/scuba2/default.cfg

   (Replace 'nano' with your preferred editor, such as 'vi' or 'emacs' or 
   'gedit') In there you can specify your default values for the SCUBA-2 scan 
   data directory ('datapath'), and where CRUSH should write its output files, 
   such as the reduced images ('outpath'). You might also want to specify where
   the Starlink 'ndf2fits' conversion tool is. E.g.:

     datapath /home/data/scuba2
     outpath ~/images
     ndf2fits /usr/local/Starlink/bin/convert/ndf2fits

   (The 'ndf2fits' setting may not be needed if the STARLINK_DIR environment 
   variable is set to point to your Starlink distribution folder...). Also,
   make sure the output directory actually exists. :-)

   You can also specify and override any of these settings ad-hoc on the 
   command line later: E.g.:

     > crush scuba2 -datapath=/home/myData -outpath=../myImages [...]


2.2. Reducing the first scans
=============================

   Now, let's reduce some data. Suppose you want to reduce pointing scan #62 
   from 2015-06-30, at 850um:

     > crush scuba2 -850um -date=20150630 -point 62  

   (The '-850um' or '-450um' options select the imaging band for the reduction,
   while the '-point' option will produce a pointing fit with fluxes displayed 
   at the end of the reduction). Suppose, you find that the pointing was off by 
   -1.2,4.6 arcsec (in Az/EL). And, suppose the flux (peak or integrated) you 
   found was too low by a factor of 1.14. You can the apply these corrections 
   (to this scan, or others) as:

     > crush scuba2 -850um -date=20150630 -center=-1.2,4.6 -scale=1.14 [...]

   Now, you are ready to reduce some science scans from the same day (say scan 
   numbers 63-66, 70 with the above pointing and 81-83 with a different 
   pointing):

     > crush scuba2 [...] -pointing=-1.2,4.6 63-66 70 -pointing=2.3,1.8 81-83

   Similarly, you can apply different calibration scalings too for the 
   different scans. In general any options will be applied to the scans that 
   are listed after them, until the same option is redefined again, or cleared
   (using -forget) or blacklisted (via -blacklist) on the command line. Thus, 
   global options should be up front before any of the scans are listed...

   The above will produce a default reduction, which is meant to work with a 
   wide variety of sources (brightness and extent), but you may do better than 
   that for your particular target. For example, if your source is faint you 
   may use the '-faint' option. For deep fields (very faint point sources) you 
   can use '-deep' which will aggressively filter the large scales... E.g.:

     > crush scuba2 -faint [...]

   or

     > crush scuba2 -deep [...]

   For very bright sources (which might be flagged excessively by the default
   settings) you may try '-bright'.

   You can find more details on pointing and calibration in the sections below.
   A more detailed general overview is in the main README (e.g. the Quick Start
   guide there, and the various advanced topics).   


2.3 Extended sources
====================

   By default, crush is optimized for reducing compact sources, and to provide 
   the cleanest possible images. This works well up to scales of 1.5 to 3 
   arcmins across (depending on how bright the source is). If you have a more 
   extended source, you can try the 'extended' option. E.g.

     > crush scuba2 -extended [...]

   or 
 
     > crush scuba2 -faint -extended [...]

   (showing that 'extended' may be combined with other options like 'faint' to
   tune the reduction for your particular source). The 'extended' option will
   recover more of the large scales (up to FoV or, for bright sources, beyond 
   the FoV -- see the corresponding section in the main README), but you will 
   pay the price of reduced sensitivity (increased noise, especially on the
   large scales).

   You can further fine-tune 'extended' mode reductions by specifying an 
   approximate source extent (FWHM) via the 'sourcesize' option (in arcsecs), 
   and by changing the number of iterations via 'rounds'. E.g.

     > crush scuba2 -extended -sourcesize=300 -rounds=20 [...]

   (The above will set the expected source size to 300" fwhm and will iterate 
   20 times.) The larger the 'sourcesize', and the more you iterate, the more 
   extended emission you will recover, but you will also see more and more 
   noise, especially on the larger scales (such as a wavy background). You need
   to make you own call as to what is best.

   You can find more information on the recovery of extended emission in 
   the main README, under the 'Advanced Topics' section.


#####################################################################
3. Reading Scans
#####################################################################


3.1 FITS vs. SDF
================

   The SCUBA-2 data are recorded in the proprietary SDF format of the JCMT.
   While the SDF files can be accessed with the Starlink software suite, the 
   format itself is not easily readable independently. Therefore, CRUSH 
   accesses these data via the Starlink suite.

   The Starlink suite provides a utility for converting SDF files to FITS,
   which is the format expected by CRUSH. The 'ndf2fits' tool usually resides 
   in the 'bin/convert' subdirectory of the Starlink installation directory. 

   You have two choices for handling the conversion. You can either do this
   manually, or let CRUSH convert the files on-the-fly, as needed. In either
   case, you will need access to the Starlink software suite. 

   Manual Conversion
   -----------------
   If you opt for manual conversion, make sure to use the 'proexts' option
   of 'ndf2fits'. E.g.:

	> ndf2fits <scan-name>.sdf <scan-name>.fits proexts

   You should name the FITS files exactly like the originals SDF ones, changing
   only the extension from '.sdf' to '.fits'.

  
   On-the-Fly Conversion
   ---------------------
   The alternative is to let CRUSH handle the conversion automatically, by 
   calling on 'ndf2fits' internally. If 'ndf2fits' is in your path, you should
   be set to go. Otherwise, you will have to instruct crush where to find the 
   'ndf2fits' executable. You can do this by editing 'default.cfg' in the 
   'scuba2' subdirectory of crush. Change the value of the 'ndf2fits' keyword 
   to indicate the location of the executable. E.g.:

        ndf2fits /usr/local/starlink/bin/convert/ndf2fits

   Alternatively, if the STARLINK_DIR environment variable is set, and points
   to the Starlink directory, as recommended by the Starlink installation, then
   the default setting (in scuba2/default.cfg):

        ndf2fits {@STARLINK_DIR}/bin/convert/ndf2fits

   will also work. If you set this up correctly, CRUSH will manage the 
   conversion of SDF files automatically, writing the FITS files in the same
   directory as the SDF.

   

3.2 '450um' vs '850um' reduction mode
=====================================

   When reducing SCUBA-2 data with CRUSH, you should specify the wavelength, in
   which you are interested. This way CRUSH will load settings that are
   appropriate for mapping in that band. You can choose between '450um' or 
   '850um' reduction modes. E.g., on the command-line:

      > crush scuba2 -450um [...]
   
   If you do not define the wavelength, then CRUSH defaults to '850um' 
   reduction.
   (The wavelength does not have to be the first argument, but should precede
   the first scan number or name in the argument list).


3.3 By date and scan number
===========================

   The preferred way of reading SCUBA-2 data is by 'date' and scan number.
   The convention of SCUBA-2 is to spread the scan data over several files.
   Data from each subarray is dumped at some intervals (typically 30s), which 
   are referred to as subscans. Thus, with two subarrays, the data for a 10 
   minute scan are typically spread over 40 files.

   (The file names begin with the subarray id, 's4a' for the current single 
   450um subarray, and 's8d' for the single 850um subarray, then continue with
   the date ('YYYYMMDD' format), scan number, and finally the subscan number.)
   
   Thus, given the location of the data ('datapath' option), the reduction 
   wavelength ('450um' or '850um'), the date (in 'YYYYMMDD' format) and the 
   scan number, CRUSH can easily find all files necessary. E.g.:

      > crush scuba2 -450um -datapath=/home/data/scuba2 -date=20100301 36

   The above line will load all usable subscans of scan #36. Some subscans
   may be designated unusable by CRUSH, either because the subscan is a dark
   measurement, or because it contains no coordinate data from the telescope, 
   or because the subscan is shorter than a preset minimum length (3s). These 
   will be dropped from the reduction queue. You can override the minimum 
   length requirement by changing or commenting the 'subscans.minlength' option
   in 'scuba2/default.cfg'

   Scan ranges can be specified as usual, e.g.:

      > crush scuba2 -date=20100301 39-42 45-48 -date=20100302 12-15 17
   
   
3.4 By file names
=================

   The alternative is to specify file names directly. You can use both full
   pathnames (which can contain wildcards and other shell-expansions) or
   give exact file names (without wildcards, etc.) relative to 'datapath'. 
   Locating scans by file names is not recommended in general, since it allows
   for processing 450um scans in '850um' mode (and vice versa) or even mixing
   the data from the different wavelengths. On the other hand, you may want
   to use file-names for locating scans, if:
	
	* your scans are named differently from the standard convention, or

	* you want to control which subscans are processed.

   For example:
	
      > crush scuba2 -450um /data/scuba2/s4a20100301_00036_0002.sdf

   or, equivalently

      > crush scuba2 -450um -datapath=/data/scuba2 s4a20100301_00036_0002.sdf

   will both process only the 2nd subscan of scan 36 (taken on 2010-03-01) in 
   '450um' mode.



#####################################################################
4. Calibration and Pointing
#####################################################################	

The default configuration of CRUSH provides approximate blind calibration, 
expected to be good to ~10% rms, when using aperture fluxes in apertures large 
enough to contain the SCUBA-2 error beams of the emission.

When using peak fluxes, the blind calibration accuracy is expected to be worse
due to the variations in main-beam efficiency with focus, elevation and
the surface quality of the JCMT.

To improve on the calibration accuracy, you can switch to a smoothed 183 GHz 
tau value based on the JCMT 183 GHz archive ('tau=jctables'), and/or provide 
order-of-unity corrections based on observations of nearby calibrator sources
(via 'scale'). E.g.


4.1 Extinction Correction
=========================

   The JCMT records both 225GHz and 183GHz opacities from radiometer 
   measurements. These are stored in the data files. By default, CRUSH uses the
   183GHz value with an appropriate scaling relation to the SCUBA-2 bands, to 
   obtain a guesstimate of the in-band opacities for the atmospheric extinction 
   correction. 

   You can get a more accurate local average value of the 183 GHz tau using the
   the 'tau=jctables' option (requires an online connection!).

      > crush scuba2 -tau=jctables <scans> [...]

   The above will download the table of measurements from the online JCMT 183 
   GHz tau archive for the date(s) of each scan, and calculate a local average
   around the time of observation within a Gaussian window (see 'tau.window'
   option in the GLOSSARY and in 'scuba2/default.cfg'). The resulting tau 
   should be more precise than the default, but is noticeably slower to obtain
   (due to the size of the tables that need to be downloaded on demand) and 
   requires a online connection.


4.2 Calibration Correction
==========================

   Even if the opacity is perfectly determined, there are remaining 
   uncertainties in the calibration. These are mainly due to the beam-quality 
   and variations thereof, due to imperfect focusing, gravitational flexing of 
   the JCMT primary with elevation, or changes in surface quality (e.g. before 
   and after a holography run). 

   Because the JCMT beams are not perfectly Gaussian (esp. at 450um), the 
   calibration scaling is also dependent on the type of flux measure used. You
   will need a different flux scaling when using apertures (of different sizes)
   or peak fluxes (for point sources). To calibrate your science target 
   properly you should first determine an order-of-unity calibration correction
   using the same flux measure (peak flux or integrated flux in the *same* 
   aperture) on a known calibrator source. You can use 

      > crush scuba2 -point [...]

   to measure both peak fluxes and fluxes in 98% inclusive apertures on compact
   calibrator sources. You can then determine a appropriate calibration scaling
   as the ratio of expected flux to observed flux. To multiply your science
   data with this scaling, use the 'scale' option of crush. E.g.:

      > crush scuba2 [...] -scale=1.23 <scans> [...]

   The blind calibration of CRUSH is based on apertures large enough to capture
   98% of the integrated source flux of point sources (including the first 
   error beam), because this measure is much less dependent on beam quality. 
   Therefore, if you are to use peak fluxes (e.g. for deep field source 
   extraction) you should pay special attention to derive appropriate 
   calibration scalings using the same method.


4.3 Pointing Corrections
========================

   You can specify incremental pointing corrections as AZ,EL offsets for every
   group of scans, the usual way using the 'pointing' option. E.g.:

      > crush scuba2 [...] -pointing=-2.3,1.6 <scans> [...]




#####################################################################
5. SCUBA-2 specific pixel divisions
#####################################################################

For a general overview of channel divisions, please consult Section 3.
(Correlated Signals) in the main README document.

   subarrays     A grouping of pixels by subarrays.

   rows          Pixel grouping by detector columns. There are 40 columns on
                 each subarray. Incidentally, the channels in a row are all
                 read out through the same SQUID mux. Thus, the group 'cols'
                 is also the grouping by SQUID multiplexer.

   cols          Pixel grouping by detector rows. There are 32 rows on each
                 subarray.

   blocks        Pixel grouping by user-specified geometric blocks of n by m
		 pixels. The size of the blocks is specified via the 'block'
		 option.   



#####################################################################
6. Glossary of SCUBA-2 specific options
#####################################################################


   450um		Select 450um imaging mode.

   850um		Select 850um imaging mode.

   block=<n>
   block=<n>x<m>	@Advanced
			Set the block size (pixels) for 'correlated.blocks'.
			The decorrelation block size will be <n> by <n>, or
			<n> by <m> pixels, depending whether there are 1 or 2
			arguments (separated by 'x').
			@See: 'correlated.blocks'

   blocks		@Alias: 'correlated.blocks'

   cols			@Alias: 'correlated.cols'
                        @Expert
                        Specifies the grouping of channels by geometric columns
			on the array, following the storage and array geometry
			convention of 32 rows by 40 columns. Since the 32 
			pixels of a 'column' are read through the same SQUID
			MUX, decorrelating on 'cols' is effectively 
			decorrelates channels that share a MUX.
			@See: 'correlated.<?>'

   he3			@Alias: 'correlated.he3'
			Remove correlations with the detector temperature (at
			the He3 stage -- hence the name). This may, or may not
			improve the sensitivity of the data.

   mirror		@Expert
			Indicate a mirrored focal plane layout. (Since one
			subarray is seen in transmission, the other in 
			reflection, through the beam-splitter, one of the
			subarray layouts is a mirror image of the other...

   ndf2fits=<path>	Specify the path to the Starlink 'ndf2fits' executable
			(usually in bin/convert subdirectory of the Starlink
			distribution. You may not need to change this option
			if the STARLINK_DIR environment variable is set to
			point to the Starlink installation folder on your 
			system, as recommended by the Starlink installation
			instructions. Otherwise, you can set this e.g.:

			  ndf2fits /usr/local/starlink/bin/convert/ndf2fits

   pixelmm=X		@Expert
			Specify the physical pixel size (separation) in mm,
			on the detector arrays.
			@See: 'platescale'

   platescale=X		@Expert
			Specify the scaling from mm on the focal plane to
			arcsec on the sky.
			@See: 'pixelmm'

   rows			@Alias: 'correlated.rows'
			@Expert
			Specifies the grouping of channels by geometric rows on
			the array, following the storage and array geometry
			convention of 32 rows by 40 columns.
			@See: 'correlated.<?>'

   <sID>.position=dX,dY	@Expert
			Set the position of pixel 0 (first row, first column)
			of subarray <sID> to dX, dY pixels from the optical 
			center. E.g.

			  s8a.position -37.3, -35.3
			
			The offset will be applied *after* any rotation.
			@See: '<sID>.rotation'

   <sID>.rotation=X	@Expert
			Set the orientation angle (degrees) of subarray <sID>
			on the focal plane. E.g.

			  s8d.rotation -90

			@See: <sID>.position'

   <sID>.scale=X	@Expert
			Set the subarray scalings. Scaling the data from the
			different subarrays such that the pixels on a subarray
			show the same response, on average, from one subarray
			to the next, is useful for maintaining calibration when
			not all subarray data is available, or when reducing
			just a select set of subarrays. E.g.:

			  s8a.scale 0.63

			@See: 'subarray'

   subarray=<list>	@Expert
			Restrict the reduction to just the specified subarrays
			at the current wavelength. The argument is a list of
			subarray letter codes (a thru d) that specify which
			subarray data to use. E.g.:

			 >crush scuba2 -850um -subarrays=a,c [...]

			Will reduce only the 850um subarrays a and c.	
			@See: '<sID>.scale'



#####################################################################
7. SCUBA-2 specific log quantities
#####################################################################

Coming soon...


   dir

   filter

   foc.X

   foc.Y

   foc.Z

   obsmode

   obspattern
  


-----------------------------------------------------------------------------
Copyright (C)2015 Attila Kovacs <attila[AT]submm.caltech.edu>
